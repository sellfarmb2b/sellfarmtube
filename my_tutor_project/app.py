import streamlit as st
import google.generativeai as genai
import os
import csv
from datetime import datetime, timedelta

# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ìˆ˜ê°•ìƒ ì „ìš© 24ì‹œê°„ í†¡", page_icon="ğŸ“")

# --- [ì„¤ì •] ---
current_dir = os.path.dirname(os.path.abspath(__file__))
data_folder_path = os.path.join(current_dir, "data")
log_file_path = os.path.join(current_dir, "chat_logs.csv")

# --- [ê¸°ëŠ¥: ëŒ€í™” ë‚´ìš© ì €ì¥] ---
# ë¡œê·¸ì¸ì€ ì—†ì§€ë§Œ, 'ìµëª…_ê²ŒìŠ¤íŠ¸'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì§ˆë¬¸ ë‚´ìš©ì€ ê³„ì† ê¸°ë¡ë©ë‹ˆë‹¤.
def save_log(user_id, question, answer):
    kst_now = datetime.utcnow() + timedelta(hours=9)
    timestamp = kst_now.strftime("%Y-%m-%d %H:%M:%S")
    file_exists = os.path.exists(log_file_path)
    with open(log_file_path, "a", newline='', encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["ì‹œê°„", "ì‚¬ìš©ì", "ì§ˆë¬¸ ë‚´ìš©", "AI ë‹µë³€"])
        writer.writerow([timestamp, user_id, question, answer])

# --- [ë©”ì¸ í™”ë©´] ---
st.title("ğŸ“ ìœ íŠœë¸Œ ì»¨ì„¤íŒ… ë´‡ (ì„ì‹œ ì˜¤í”ˆ)")
st.caption("ë¡œê·¸ì¸ ì—†ì´ ììœ ë¡­ê²Œ ì´ìš© ê°€ëŠ¥í•œ ì„ì‹œ ë²„ì „ì…ë‹ˆë‹¤.")

# ì‚¬ìš©ì IDë¥¼ 'ìµëª…'ìœ¼ë¡œ ê³ ì •
if "user_id" not in st.session_state:
    st.session_state["user_id"] = "ìµëª…_ê²ŒìŠ¤íŠ¸"

# API í‚¤ ì„¤ì •
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except:
    st.error("API í‚¤ ì„¤ì • ì˜¤ë¥˜")
    st.stop()

# ê°•ì˜ ìë£Œ ë¡œë”©
@st.cache_resource
def load_knowledge_base():
    knowledge_text = ""
    if not os.path.exists(data_folder_path):
        return ""
    files = [f for f in os.listdir(data_folder_path) if f.endswith('.txt')]
    for file in files:
        with open(os.path.join(data_folder_path, file), "r", encoding="utf-8") as f:
            knowledge_text += f"\n\n--- {file} ---\n\n" + f.read()
    return knowledge_text

knowledge_base = load_knowledge_base()

system_instruction = f"""
ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì±„ë„ ì„±ì¥, ì•Œê³ ë¦¬ì¦˜, ê¸°íš, ìˆ˜ìµí™” ë“± ëª¨ë“  ë¶„ì•¼ë¥¼ í†µë‹¬í•œ **'15ë…„ ì°¨ ìµœê³ ì˜ ìœ íŠœë¸Œ ì»¨ì„¤í„´íŠ¸'**ì…ë‹ˆë‹¤.
**[ë‹¹ì‹ ì˜ í–‰ë™ ì§€ì¹¨]**
1. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì´ [ê°•ì˜ ìë£Œ]ì— ìˆë‹¤ë©´, ê·¸ ë‚´ìš©ì„ í•µì‹¬ ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. [ê°•ì˜ ìë£Œ]ì— ì—†ë”ë¼ë„, ì ˆëŒ€ "ìë£Œì— ì—†ë‹¤"ê³  ë§í•˜ì§€ ë§ê³  ë‹¹ì‹ ì˜ ì „ë¬¸ ì§€ì‹ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
3. ìˆ˜ê°•ìƒì„ ê²©ë ¤í•˜ëŠ” ë”°ëœ»í•œ ë©˜í† ì˜ ë§íˆ¬("~ì…ë‹ˆë‹¤", "~í•˜ì…”ì•¼ í•´ìš”")ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

**[ê°•ì˜ ìë£Œ]**
{knowledge_base}
"""

model = genai.GenerativeModel(
    model_name="gemini-2.5-flash", 
    system_instruction=system_instruction
)

# í™”ë©´ ê·¸ë¦¬ê¸°
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì§ˆë¬¸ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ì‘ì„± ì¤‘..."):
            try:
                recent_history = []
                for m in st.session_state.messages[-10:]:
                     role = "model" if m["role"] == "assistant" else "user"
                     recent_history.append({"role": role, "parts": [m["content"]]})

                chat = model.start_chat(history=recent_history[:-1])
                response = chat.send_message(prompt)
                
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
                # ìµëª…ìœ¼ë¡œ ëŒ€í™” ë‚´ìš© ì €ì¥
                save_log(st.session_state["user_id"], prompt, response.text)
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {e}")